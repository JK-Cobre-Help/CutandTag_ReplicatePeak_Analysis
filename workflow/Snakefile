configfile: "config/config.yml"

##################################################################
##                    Define input functions                    ##
##################################################################

# Author: Kevin Boyd
# Date: Dec 4, 2024
# Adapted from: "https://github.com/SansamLab-Pipelines-Genomics/ReplicatePeakAnalyzer"

import pandas as pd
import shutil
import common_functions as cf
from datetime import datetime
now = datetime.now()
tmstmp = str(now.strftime("%y%m%d_%H%M"))

def BamFiles_dict_from_samples(sample, samples_table):

    # Get a set of treatment BAM file names for the sample from the samples table
    bam_lst = set(samples_table.loc[samples_table["sample"] == str(sample), "sampleBam"].to_list())

    # Join the list of BAM file names with a space separator and return the resulting string
    return ' '.join([str(item) for item in bam_lst])

def filter_sample_by_set(Set,samples_Table):
    """
    This function takes a 'set' value as input and returns a list containing
    the unique sample names corresponding to the given 'set' value from a pandas dataframe.
    """
    # Filter the DataFrame to include only rows with the desired 'merged_sample' value
    filtered_rows = samples_Table[samples_Table['set'] == Set]

    # Convert the 'sample' column from 'filtered_rows' to a list, remove duplicates by converting it to a set and then back to a list
    unique_samples = list(set(filtered_rows['sample'].tolist()))
    
    # Return the dictionary containing the filtered samples
    return unique_samples

# this reads the CSV file and sets an index using the values in the "sample" column.
samples_table = pd.read_csv(config["samples_csv"]).set_index("sample", drop=False)
# convert all values in dataframe to strings
samples_table = samples_table.applymap(str)
# make a samples list
samples_lst = samples_table['sample'].to_list()


##################################################################
##                          rule all                            ##
##################################################################

rule all:
    input:
        expand("results/consensusPeaks/{Set}_consensus_peaks.bam", Set=list(set(samples_table['set']))),
        expand("results/consensusPeaks/{Set}_consensus_peaks.bw", Set=list(set(samples_table['set'])))

# Call peaks with MACS2
rule call_peaks_with_macs2:
    input:
        bam="results/processed/{sample}.bam"
    output:
        peaks="results/macs2Peaks/{sample}_peaks.narrowPeak",
        summary="results/macs2Peaks/{sample}_macs2Peak_summary.txt"
    params:
        genome=config["genome"],
        qvalue=config["macs2_qvalue"],
        sample_name="{sample}",
        output_dir="results/macs2Peaks/"
    shell:
        """
        macs2 callpeak -t {input.bam} \
        -g {params.genome} -f BAMPE -n {params.sample_name}_{params.qvalue} \
        --outdir {params.output_dir} -q {params.qvalue} --keep-dup all --nomodel \
        2>{params.output_dir}/{params.sample_name}_macs2Peak_summary.txt
        """

# Generate consensus peaks from replicates
rule generate_consensus_peaks:
    input:
        lambda wildcards: expand(
            "results/macs2Peaks/{sample}_peaks.narrowPeak",
            sample=filter_sample_by_set(wildcards.Set, samples_table)
        )
    output:
        consensus="results/consensusPeaks/{Set}_consensus_peaks.rds"
    params:
        min_overlap=config["minNumberOfSampleOverlaps"]
    script:
        "scripts/reportOverlappingPeaks.R"

# Filter consensus peaks to BED format
rule make_bed_of_reproducible_peaks:
    input:
        "results/consensusPeaks/{Set}_consensus_peaks.rds"
    output:
        "results/consensusPeaks/{Set}_consensus_peaks.bed"
    params:
        min_overlap=config["minNumberOfSampleOverlaps"]
    script:
        "scripts/make_bed_of_reproducible_peaks.R"

# Create BigWig files from consensus peaks
rule create_bigwig_from_consensus:
    input:
        bam="results/processed/{Set}_consensus_peaks.bam"
    output:
        bigwig="results/consensusPeaks/{Set}_consensus_peaks.bw"
    params:
        bin_size=config["binSize"],
        genome_size=config["effective_genome_size"]
    shell:
        """
        bamCoverage --bam {input.bam} --outFileName {output.bigwig} \
        --binSize {params.bin_size} --effectiveGenomeSize {params.genome_size} --normalizeUsing CPM
        """
